{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58027ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RUN THIS IN GOOGLE COLAB (AFTER RESTARTING RUNTIME) ---\n",
    "\n",
    "# 1. Install specific versions that work with Qwen2-VL\n",
    "# We use vllm 0.6.4.post1 which contains the fix for the 'make_batched_images' error\n",
    "print(\"‚è≥ Installing dependencies... (This takes about 2-3 minutes)\")\n",
    "!pip install vllm==0.6.4.post1\n",
    "!pip install transformers==4.46.1\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Login to ngrok (Replace with your token)\n",
    "from pyngrok import ngrok\n",
    "# ENTER YOUR TOKEN BELOW\n",
    "ngrok.set_auth_token(\"36w3cwHtS4SvmUtDwo24VUcm22M_5AMVMsCmiibBMHYwfUNrc\")\n",
    "\n",
    "# 3. Open the Tunnel\n",
    "public_url = ngrok.connect(8000).public_url\n",
    "print(f\"\\nAPI URL IS: \\n{public_url}/v1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m vllm.entrypoints.openai.api_server \\\n",
    "  --model Qwen/Qwen2-VL-7B-Instruct-AWQ \\\n",
    "  --quantization awq \\\n",
    "  --gpu-memory-utilization 0.90 \\\n",
    "  --max-model-len 8192 \\\n",
    "  --dtype half \\\n",
    "  --port 8000 \\\n",
    "  --trust-remote-code \\\n",
    "  --enforce-eager"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
