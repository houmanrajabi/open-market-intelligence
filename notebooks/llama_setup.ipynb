{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Install vLLM\n",
    "  pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Start server with Llama-3-8B-Instruct\n",
    "  vllm serve meta-llama/Meta-Llama-3-8B-Instruct \\\n",
    "      --port 8000 \\\n",
    "      --host 0.0.0.0 \\\n",
    "      --max-model-len 4096 \\\n",
    "      --dtype auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f25e20",
   "metadata": {},
   "source": [
    "# colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RUN THIS IN GOOGLE COLAB (AFTER RESTARTING RUNTIME) ---\n",
    "\n",
    "# 1. Install specific versions that work with Qwen2-VL\n",
    "# We use vllm 0.6.4.post1 which contains the fix for the 'make_batched_images' error\n",
    "print(\"‚è≥ Installing dependencies... (This takes about 2-3 minutes)\")\n",
    "!pip install vllm==0.6.4.post1\n",
    "!pip install transformers==4.46.1\n",
    "!pip install pyngrokb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb61404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Login to ngrok (Replace with your token)\n",
    "from pyngrok import ngrok\n",
    "# ENTER YOUR TOKEN BELOW\n",
    "ngrok.set_auth_token(\"36w3cwHtS4SvmUtDwo24VUcm22M_5AMVMsCmiibBMHYwfUNrc\")\n",
    "\n",
    "# 3. Open the Tunnel\n",
    "public_url = ngrok.connect(8000).public_url\n",
    "print(f\"\\nAPI URL IS: \\n{public_url}/v1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !vllm serve meta-llama/Meta-Llama-3-8B-Instruct \\\n",
    "!vllm serve casperhansen/llama-3-8b-instruct-awq \\\n",
    "    --quantization awq \\\n",
    "    --port 8000 \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --max-model-len 4096 \\\n",
    "    --dtype half \\\n",
    "    --gpu-memory-utilization 0.95"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
