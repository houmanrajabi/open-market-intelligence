# =============================================================================
# FOMC RAG Pipeline Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Data Directories
# -----------------------------------------------------------------------------
DATA_DIR=./data
RAW_DATA_DIR=./data/raw
PROCESSED_DATA_DIR=./data/processed
TEST_SET_DIR=./data/test_set
VECTOR_DB_DIR=./data/vector_db

# -----------------------------------------------------------------------------
# FOMC Document Download Settings
# -----------------------------------------------------------------------------
FOMC__START_YEAR=2020
FOMC__END_YEAR=2025
FOMC__BASE_URL=https://www.federalreserve.gov/monetarypolicy
FOMC__OUTPUT_DIR=data/raw/
FOMC__TIMEOUT=10
# FOMC__TARGET_DOCS=minutes,statement,presconf,sep,implementation

# -----------------------------------------------------------------------------
# Processing Settings
# -----------------------------------------------------------------------------
# Chunking
PROCESSING__CHUNK_SIZE=512
PROCESSING__CHUNK_OVERLAP=50
PROCESSING__MIN_CHUNK_SIZE=100
PROCESSING__MAX_CHUNK_SIZE=1024
PROCESSING__STRATEGY=section_aware

# Quality
PROCESSING__QUALITY_THRESHOLD=0.5
PROCESSING__SIMILARITY_THRESHOLD=0.7

# Table Handling
PROCESSING__PRESERVE_LARGE_TABLES=true
PROCESSING__SMALL_TABLE_THRESHOLD=150
PROCESSING__MULTIMODAL_CHUNKS=true

# Image Processing
PROCESSING__PDF_DPI=300
PROCESSING__IMAGE_MAX_SIZE=1600
PROCESSING__IMAGE_QUALITY=95
PROCESSING__EXTRACT_FIGURES=true

# VLM API (Qwen2-VL)
PROCESSING__VLM_API_URL=https://your-ngrok-url.ngrok-free.dev/v1
PROCESSING__VLM_MODEL=Qwen/Qwen2-VL-72B-Instruct-AWQ
PROCESSING__VLM_API_KEY=your-production-key
PROCESSING__VLM_MAX_RETRIES=3
PROCESSING__VLM_TEMPERATURE=0.01
PROCESSING__VLM_MAX_TOKENS=4096

# Parallel Processing (Future Use)
PROCESSING__MAX_WORKERS=4
PROCESSING__ENABLE_PARALLEL=false

# -----------------------------------------------------------------------------
# Vector Database Settings (ChromaDB)
# -----------------------------------------------------------------------------
VECTORDB__COLLECTION_NAME=fomc_documents
VECTORDB__EMBEDDING_DIM=384
VECTORDB__DISTANCE_METRIC=cosine
VECTORDB__BATCH_SIZE=500

# Index Settings (HNSW)
VECTORDB__HNSW_EF=200
VECTORDB__HNSW_M=16

# -----------------------------------------------------------------------------
# Embedding Model Settings
# -----------------------------------------------------------------------------
EMBEDDING__MODEL_NAME=BAAI/bge-small-en-v1.5
EMBEDDING__DEVICE=  # Leave empty for auto-detect (cuda/mps/cpu)
EMBEDDING__BATCH_SIZE=32
EMBEDDING__NORMALIZE_EMBEDDINGS=true
EMBEDDING__MAX_SEQ_LENGTH=512

# Instruction Prefixes (for instruction-tuned models)
EMBEDDING__QUERY_INSTRUCTION=Represent this sentence for searching relevant passages: 
EMBEDDING__DOC_INSTRUCTION=

# -----------------------------------------------------------------------------
# Retrieval Settings (RAG)
# -----------------------------------------------------------------------------
RETRIEVAL__TOP_K=5
RETRIEVAL__RERANK=false
RETRIEVAL__RERANK_TOP_K=10

# LLM Settings
RETRIEVAL__LLM_PROVIDER=openai
RETRIEVAL__LLM_MODEL=gpt-4
RETRIEVAL__LLM_TEMPERATURE=0.1
RETRIEVAL__MAX_CONTEXT_LENGTH=4000

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
LOGGING__LEVEL=INFO
LOGGING__LOG_FILE=./logs/fomc_rag.log
LOGGING__INCLUDE_CONSOLE=true

# LLM Settings (vLLM Remote Inference)
  LLM__API_BASE_URL=http://your-vastai-instance:8000/v1
  LLM__API_KEY=EMPTY
  LLM__MODEL_NAME=meta-llama/Meta-Llama-3-8B-Instruct
  LLM__TEMPERATURE=0.1
  LLM__MAX_TOKENS=512

  # Entropy Thresholds
  LLM__ENTROPY_EXPANSION_THRESHOLD=1.5
  LLM__ENTROPY_ABSTENTION_THRESHOLD=2.0

  # Retrieval
  RETRIEVAL__TOP_K=5
  RETRIEVAL__EXPANDED_TOP_K=10

# -----------------------------------------------------------------------------
# Alignment Settings (RLAIF/DPO Training)
# -----------------------------------------------------------------------------
# Teacher Model (GPT-4 for grading)
ALIGNMENT__TEACHER_MODEL=gpt-4-turbo
ALIGNMENT__TEACHER_API_KEY=  # OpenAI API key
ALIGNMENT__TEACHER_TEMPERATURE=0.1

# Grading Criteria
ALIGNMENT__WIN_THRESHOLD=7.0
ALIGNMENT__FACTUAL_GROUNDING_WEIGHT=0.4
ALIGNMENT__CITATION_ACCURACY_WEIGHT=0.3
ALIGNMENT__ABSTENTION_QUALITY_WEIGHT=0.2
ALIGNMENT__HALLUCINATION_PENALTY_WEIGHT=0.1
ALIGNMENT__MIN_SCORE_GAP=0.5

# Preference Pair Generation
PAIRS_DIR=./data/alignment/preference_pairs

# DPO Training Hyperparameters
ALIGNMENT__DPO_BETA=0.1
ALIGNMENT__DPO_LEARNING_RATE=5e-7
ALIGNMENT__DPO_NUM_EPOCHS=3
ALIGNMENT__DPO_BATCH_SIZE=4
ALIGNMENT__DPO_GRADIENT_ACCUMULATION_STEPS=4

# LoRA Configuration
ALIGNMENT__USE_LORA=true
ALIGNMENT__LORA_R=16
ALIGNMENT__LORA_ALPHA=32
ALIGNMENT__LORA_DROPOUT=0.05
# ALIGNMENT__LORA_TARGET_MODULES=q_proj,v_proj,k_proj,o_proj  # comma-separated

# Quantization
ALIGNMENT__USE_4BIT=true
ALIGNMENT__BNB_4BIT_COMPUTE_DTYPE=bfloat16

# Model Configuration
ALIGNMENT__STUDENT_MODEL_NAME=meta-llama/Meta-Llama-3-8B-Instruct
ALIGNED_MODEL_DIR=./models/llama3_dpo_aligned

# Training Control
ALIGNMENT__DPO_MAX_LENGTH=512
ALIGNMENT__DPO_MAX_PROMPT_LENGTH=256
ALIGNMENT__DPO_WARMUP_STEPS=100
ALIGNMENT__DPO_SAVE_STEPS=100
ALIGNMENT__DPO_LOGGING_STEPS=10
ALIGNMENT__DPO_FP16=false
ALIGNMENT__DPO_BF16=true

# -----------------------------------------------------------------------------
# Evaluation Settings
# -----------------------------------------------------------------------------
EVALUATION__EVAL_OUTPUT_DIR=./data/evaluation
EVALUATION__ACCURACY_THRESHOLD=0.7
EVALUATION__DEFAULT_TEST_SET=./data/test_set/sample_test_questions.json
EVALUATION__COMPUTE_RETRIEVAL_METRICS=true
EVALUATION__COMPUTE_ANSWER_METRICS=true
EVALUATION__COMPUTE_UNCERTAINTY_METRICS=true
EVALUATION__ECE_BINS=10